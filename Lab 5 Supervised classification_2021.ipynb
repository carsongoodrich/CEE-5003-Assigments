{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 5: Supervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ATENTION:*** before running this lab, upgrade geemap, please go to File, New, Terminal, and pass the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install -U geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "The purpose of this lab is introduce you to concepts of supervised classification: prediction of nominal or numeric values of a geographic variable from other geographic variables.  You will explore processes of training data collection, classifier selection, classifier training, image classification and accuracy assessment.  At the completion of the lab, you will be able to perform supervised classification in Earth Engine.\n",
    "\n",
    "**Prerequisites:** Lab 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to classification and regression\n",
    "For present purposes, define prediction as guessing the value of some geographic variable of interest *g*, using a function *G* that takes as input a pixel vector **p**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "G_{T}(p_i) = g_i \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *i* in this equation refers to a particular instance from a set of pixels.  Think of *G* as a guessing function and *gi* as the guess for pixel *i*.   The **T** in the subscript of *G* refers to a *training set* (a set of known values for p and the correct g), used to infer the structure of G.  You have to choose a suitable *G* to train with **T**.  When *g* is nominal (e.g. {'water', 'vegetation', 'bare'}), call this setup classification.  When g is numeric, call this setup regression.  This is an incredibly simplistic description of a problem addressed in a broad range of fields including mathematics, statistics, data mining, machine learning, etc.  Interested readers may see [Witten et al. (2011)](http://www.cs.waikato.ac.nz/ml/weka/book.html), [Hastie et al. (2009)](http://statweb.stanford.edu/~tibs/ElemStatLearn/) or [Goodfellow et al (2016)](http://www.deeplearningbook.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Classification\n",
    "Classification in Earth Engine has a similar workflow to regression: build the training, train the classifier, classify an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification, g is nominal.  The first step is to create training data manually.  (Alternatively, upload a shapefile  training data (of points or polygons), for example data collected on the ground with a GPS).  Using Google Earth we can also digitize training polygons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "import geemap\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import a Landsat 8 image for San Francisco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point([-111, 42])\n",
    "# point = ee.Geometry.Point([-87.7719, 41.8799])\n",
    "\n",
    "landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "    .filterBounds(point) \\\n",
    "    .filterDate('2021-05-01', '2021-07-31') \\\n",
    "    .sort('CLOUD_COVER') \\\n",
    "    .first() \\\n",
    "    .select('SR_B[1-7]')\n",
    "\n",
    "landsat = landsat.multiply(0.0000275).add(-0.2)\n",
    "\n",
    "\n",
    "vis_params = {\n",
    "    'min': 0,\n",
    "    'max': 0.2,\n",
    "    'bands': ['SR_B5', 'SR_B4', 'SR_B3']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# landsat = landsat.updateMask(waterMask)\n",
    "# print(landsat.getInfo())\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(landsat, vis_params, 'false color composite')\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define areas that have unique characteristics: bare soil, water, vegetation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use NDVI for help in diferentiating these areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name ='ndvi'\n",
    "ndvi=landsat.normalizedDifference(['SR_B5', 'SR_B4'])\n",
    "\n",
    "vis_params = {\n",
    "  'min': -0.2,\n",
    "  'max': 1.0,\n",
    "  'palette': ['blue','white','brown','yellow', 'lime', 'green','navy']}\n",
    "\n",
    "Map.addLayer(ndvi,vis_params,img_name)\n",
    "\n",
    "colors = vis_params['palette']\n",
    "vmin = vis_params['min']\n",
    "vmax = vis_params['max']\n",
    "\n",
    "Map.add_colorbar_branca(colors=colors, vmin=vmin, vmax=vmax, layer_name=img_name)\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training dataset\n",
    "\n",
    "There are several ways you can create a region for generating the training dataset.\n",
    "\n",
    "- Draw a shape (e.g., rectangle) on the map and the use `region = Map.user_roi`\n",
    "- Define a geometry, such as `region = ee.Geometry.Rectangle([-122.6003, 37.4831, -121.8036, 37.8288])`\n",
    "- Create a buffer zone around a point, such as `region = ee.Geometry.Point([-122.4439, 37.7538]).buffer(10000)`\n",
    "- If you don't define a region, it will use the image footprint by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR BARE SOIL: \\\n",
    "# how I did this: \n",
    "# 1. I zoomed into the Landsat image to a bare soil area\n",
    "# 2. Click on the polygon icon of the left, and define an area with points, forming a closed polygon\n",
    "# 3. Run this cell. The last draw polygon is stored in \"Map.user_roi\"\n",
    "polygon = Map.user_roi\n",
    "\n",
    "# Or you can enter defined coordinates as the commented lines below.\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([[-112.401, 41.401],[-112.370, 41.546],[-112.367, 41.520],[-112.402, 41.521]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "baresoil = ee.Feature(polygon, {'class': 2, 'name': 'bare soil'});\n",
    "Map.addLayer(baresoil, {'fill_color':'yellow', 'outline': 1}, name='baresoil')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR VEGETATION\n",
    "# same procedure for water and soil, in this case I looked into a forest area\n",
    "polygon = Map.user_roi\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([[-111.996, 41.597],[-111.988,41.595],[-111.987, 41.591],[-111.996, 41.591]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "vegetation = ee.Feature(polygon, {'class': 1, 'name': 'vegetation'});\n",
    "Map.addLayer(vegetation, {'fill_color':'green', 'outline': 1}, name='vegetation')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR WATER\n",
    "# same procesure as described for soil, in this case, I looked at water areas\n",
    "# \n",
    "polygon = Map.user_roi\n",
    "\n",
    "# // Create an ee.Geometry.\n",
    "polygon = ee.Geometry.Polygon([[-111.335, 42.033],[-111.292, 42.033],[-111.292, 42.000],[-111.3359, 42.000]]);\n",
    "\n",
    "# // Create a Feature from the Geometry.\n",
    "water = ee.Feature(polygon, {'class': 0, 'name': 'water'});\n",
    "Map.addLayer(water, {'fill_color':'blue', 'outline': 1}, name='water')\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR BARESOIL again\n",
    "# # same procesure as described for soil, in this case, I looked at a misclassified area\n",
    "# # \n",
    "# polygon = Map.user_roi\n",
    "\n",
    "# # // Create an ee.Geometry.\n",
    "# polygon = ee.Geometry.Polygon([[-113.522, 42.115],[-113.512, 42.115],[-113.513, 42.106],[-113.522, 42.107]]);\n",
    "\n",
    "# #// Create a Feature from the Geometry.\n",
    "# baresoil1 = ee.Feature(polygon, {'class': 2, 'name': 'baresoil1'});\n",
    "# Map.addLayer(baresoil1, {'fill_color':'yellow', 'outline': 1}, name='baresoil1')\n",
    "# Map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Features into a Feature Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingFeatures = ee.FeatureCollection([water, vegetation, baresoil])\n",
    "# trainingFeatures = ee.FeatureCollection([water, vegetation, baresoil, baresoil1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the bands of the Landsat composite to be used as predictors (i.e. the elements of p):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionBands = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5' ,'SR_B6','SR_B7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the merged FeatureCollection, each Feature should have a property called 'class' where the classes are consecutive integers, one for each class, starting at 0. Verify that this is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[-111.335, 42.033], [-111.3359, 42], [-111.292, 42], [-111.292, 42.033], [-111.335, 42.033]]]}, 'id': '0', 'properties': {'class': 0, 'name': 'water'}}\n"
     ]
    }
   ],
   "source": [
    "print(trainingFeatures.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Create a training set T for the classifier by sampling the Landsat composite with the merged features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierTraining = landsat.select(predictionBands).sampleRegions(\n",
    "      collection= trainingFeatures, \n",
    "      properties= ['class'], \n",
    "      scale= 30\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Randomly split the data into 60% for training, and 40% for testing\n",
    "trainingTesting = classifierTraining.randomColumn('random',111009);\n",
    "\n",
    "training = trainingTesting.filter(ee.Filter.lt('random', 0.66));\n",
    "\n",
    "testing = trainingTesting.filter(ee.Filter.gte('random', 0.66));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Non-linear regression functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a pletora of options for classification in Google Earth Engine. Here is an screenshot of these options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.imgur.com/vROsEiq.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ![](https://i.imgur.com/vROsEiq.png)\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://i.imgur.com/vROsEiq.png\")#, width=100, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For example, a Classification and Regression Tree (CART, see Brieman et al. 1984) is a machine learning algorithm that can learn non-linear patterns in your data.  Reusing the T table (without the constant term), train a CART as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter to tune\n",
    "leaf_val=1\n",
    "\n",
    "cartclassifier = ee.Classifier.smileCart(minLeafPopulation=leaf_val).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make predictions over the input imagery (classify in this context is a misnomer):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cartClasifficationImage = landsat.select(predictionBands).classify(cartclassifier);\n",
    "\n",
    "Map.addLayer(cartClasifficationImage, {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']},'CART classification');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameter to tune\n",
    "trees_val=13\n",
    "\n",
    "rfClassification = ee.Classifier.smileRandomForest(numberOfTrees=trees_val, seed=111009).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "rfClassificationImage = landsat.select(predictionBands).classify(rfClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(rfClassificationImage,  {'min': 0, 'max': 2,\n",
    "                                   'palette':['blue','green', 'yellow']}, 'RF classification');\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter to tune\n",
    "gamma_val =0.1\n",
    "\n",
    "# // Create an SVM classifier with custom parameters.\n",
    "svClassification = ee.Classifier.libsvm(svmType='C_SVC',kernelType='RBF',gamma=gamma_val).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9e947276db471aa02061f7d4225680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=24628.0, center=[42, -111], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# // Perform the RF regression on the landsat image\n",
    "svClassificationImage = landsat.select(predictionBands).classify(svClassification);\n",
    "    \n",
    "# // Visualize the RF regression\n",
    "Map.addLayer(svClassificationImage,{'min': 0, 'max': 2,\n",
    "                                   'palette':['blue', 'green','yellow']}, 'SV CLassification');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classification context, accuracy measurements are often derived from a [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the confusion matrix and expand the object to inspect the matrix.  The entries represent number of pixels.  Items on the diagonal represent correct classification.  Items off the diagonal are misclassifications, where the class in row i is classified as column j.  It's also possible to get basic descriptive statistics from the confusion matrix.  For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a confusion matrix?\n",
    "\n",
    "A confusion matrix is used here to compare two different data, one the true value and the other the predicted values. We will be using it primarily to compute overall accuracy between the model and the different machine learning results, but confusion matrices also provide explicit information about which  classes were classified incorrectly; not just if pixels were classified incorrectly, but what class they were incorrectly classified as. For an example of how to use and interpret a confusion matrix for LULC remote sensing visit https://www.harrisgeospatial.com/docs/CalculatingConfusionMatrices.html and \n",
    "http://gsp.humboldt.edu/olm_2019/courses/GSP_216_Online/lesson6-2/metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Perform the CART classification on the test set\n",
    "\n",
    "test=testing.classify(cartclassifier)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix\n",
      "[[4969    0    0]\n",
      " [   0  136    1]\n",
      " [   0    0 5840]]\n",
      "Overall Accuracy: 0.9999086424264572\n",
      "Producers Accuracy: [[1], [0.9927007299270073], [1]]\n",
      "Consumers Accuracy: [[1, 1, 0.9998287964389659]]\n",
      "Kappa: 0.9998205393809737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix\n",
      "[[4969    0    0]\n",
      " [   0  136    1]\n",
      " [   0    0 5840]]\n",
      "Overall Accuracy: 0.9999086424264572\n",
      "Producers Accuracy: [[1], [0.9927007299270073], [1]]\n",
      "Consumers Accuracy: [[1, 1, 0.9998287964389659]]\n",
      "Kappa: 0.9998205393809737\n"
     ]
    }
   ],
   "source": [
    "# // Perform the RF classification on the test set\n",
    "\n",
    "test=testing.classify(rfClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConfusionMatrix\n",
      "[[4969    0    0]\n",
      " [   0  137    0]\n",
      " [   0    0 5840]]\n",
      "Overall Accuracy: 1\n",
      "Producers Accuracy: [[1], [1], [1]]\n",
      "Consumers Accuracy: [[1, 1, 1]]\n",
      "Kappa: 1\n"
     ]
    }
   ],
   "source": [
    "# // Perform the SVR classification on the test set\n",
    "\n",
    "test=testing.classify(svClassification)\n",
    "# print(test.first().getInfo())\n",
    "# // Get a confusion matrix representing expected accuracy.\n",
    "testAccuracy = test.errorMatrix('class', 'classification');\n",
    "\n",
    "errormaxtrix=np.array(testAccuracy.array().getInfo())\n",
    "\n",
    "print(testAccuracy.name());\n",
    "print(errormaxtrix)\n",
    "print('Overall Accuracy:', testAccuracy.accuracy().getInfo());\n",
    "print('Producers Accuracy:', testAccuracy.producersAccuracy().getInfo());\n",
    "print('Consumers Accuracy:', testAccuracy.consumersAccuracy().getInfo());\n",
    "print('Kappa:', testAccuracy.kappa().getInfo());\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS: Hyperparameters tuning\n",
    "\n",
    "A random forest is a collection of random trees the predictions of which are used to compute an average (regression) or vote on a label (classification).  Note that the only parameter to the classifier is the number of trees.  How many trees should you use?  Making that choice is best done by hyperparameter tuning.  For example, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTrees = ee.List.sequence(1, 4, 1)\n",
    "\n",
    "\n",
    "def trees(t):\n",
    "    rfclass = ee.Classifier.smileRandomForest(numberOfTrees=t, seed=111009).train(\n",
    "    features= training, \n",
    "    classProperty= 'class', \n",
    "    inputProperties= predictionBands)\n",
    "    \n",
    "    rfTesting = testing.classify(rfclass)\n",
    "    testAccuracy = rfTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_trees=numTrees.map(trees)\n",
    "value_info = kappa_trees.getInfo()\n",
    "\n",
    "# print(rmse_trees.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['numTrees'] = numTrees.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='numTrees', \n",
    "             y='kappa',\n",
    "             title= 'Impact of Number of Trees in Random Forest'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_vals = ee.List.sequence(0.01, 0.2, 0.05)\n",
    "\n",
    "\n",
    "def gammas(t):\n",
    "    svclass = ee.Classifier.libsvm(svmType='C_SVC',kernelType='RBF',gamma=t).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )\n",
    "    \n",
    "    svTesting = testing.classify(svclass)\n",
    "    testAccuracy = svTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_gama=gamma_vals.map(gammas)\n",
    "value_info = kappa_gama.getInfo()\n",
    "\n",
    "# print(rmse_gama.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['Gamma'] = gamma_vals.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='Gamma', \n",
    "             y='kappa',\n",
    "             title= 'Impact of Gamma in SV'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now for Cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_vals = ee.List.sequence(1, 5, 1)\n",
    "\n",
    "\n",
    "def leaves(t):\n",
    "    cartclass= ee.Classifier.smileCart(minLeafPopulation=t).train(\n",
    "      features= training, \n",
    "      classProperty= 'class', \n",
    "      inputProperties= predictionBands\n",
    "    )\n",
    "    \n",
    "    cartTesting = testing.classify(cartclass)\n",
    "    testAccuracy = cartTesting.errorMatrix('class', 'classification');\n",
    "    kappa= testAccuracy.kappa();       \n",
    "    return kappa\n",
    "\n",
    "\n",
    "kappa_leaf=leaf_vals.map(leaves)\n",
    "value_info = kappa_leaf.getInfo()\n",
    "\n",
    "# print(rmse_gama.getInfo())\n",
    "\n",
    "import pandas as pd\n",
    "df =pd.DataFrame(value_info,columns=['kappa'])\n",
    "df['leaf'] = leaf_vals.getInfo() \n",
    "\n",
    "ax =df.plot.line(x='leaf', \n",
    "             y='kappa',\n",
    "             title= 'Impact of minLeafPopulation in cart'\n",
    "             )\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "\n",
    "Recreate this notebook for Logan UT, and add 3 more polygons that describe soil, vegetation and water (there must be 3 polygons per class). Make sure your CART, SVC and Random Forest uses the tuned hyperparameters when discussing your accuracy found. Are the models behaving similarly? Do they statistically perform different than this example? Discuss it.\n",
    "\n",
    "Note: if after a while the code does not run, or shows an error, reduce the size of the polygons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
